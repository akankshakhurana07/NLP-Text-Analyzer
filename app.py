import streamlit as st
matplotlib.use("Agg")
import spacy
from spacy.lang.fr.stop_words import STOP_WORDS as FR_STOP
from spacy.lang.en.stop_words import STOP_WORDS as EN_STOP
from string import punctuation
from heapq import nlargest
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd

st.set_page_config(page_title="NLP Text Analyzer", page_icon="ğŸŒ", layout="wide")

# â”€â”€ CSS â”€â”€
st.markdown("""<style>
:root { --bg:#0e0f11; --card:#161820; --card2:#1c1e28; --gold:#c8a96e; --txt:#e8e6e0; --mute:#6b6b73; --bdr:#2a2c35; }
.stApp { background:var(--bg) !important; color:var(--txt) !important; font-family:'Segoe UI',sans-serif; }
#MainMenu, footer, .stToolbar { visibility:hidden; }
.block-container { padding-top:1.5rem !important; max-width:1300px !important; }
.stSidebar { background:#111214 !important; border-right:1px solid var(--bdr); }

.card { background:var(--card); border:1px solid var(--bdr); border-radius:12px; padding:1.1rem 1.2rem; margin-bottom:12px; }

.stButton button { background:var(--gold) !important; color:#0e0f11 !important; font-weight:600 !important; border:none !important; border-radius:8px !important; cursor:pointer; transition:background .15s, transform .1s, box-shadow .15s; }
.stButton button:hover { background:#dbbe7e !important; box-shadow:0 0 14px rgba(200,169,110,.5); }
.stButton button:active { transform:scale(0.93); background:#a88a55 !important; }

.stTextarea textarea, .stTextInput input { background:var(--card2) !important; color:var(--txt) !important; border:1px solid var(--bdr) !important; border-radius:8px !important; }
.stTextarea label, .stSlider label, .stSelectbox label { color:var(--mute) !important; font-size:.78rem !important; }

.stTabs button[role="tab"] { color:var(--mute) !important; font-size:.82rem !important; }
.stTabs button[role="tab"][aria-selected="true"] { color:var(--gold) !important; border-bottom-color:var(--gold) !important; }

.token-tag { border-radius:8px; padding:4px 9px; display:inline-flex; flex-direction:column; gap:1px; margin:3px; }
.token-tag .token-word { font-size:.84rem; font-weight:600; }
.token-tag .token-meta { font-size:.64rem; opacity:.7; }
.pos-NOUN  { background:#2e3a52; color:#7eaee0; }
.pos-VERB  { background:#3a2e52; color:#b07ee0; }
.pos-ADJ   { background:#2e4a3a; color:#7ee0a8; }
.pos-ADV   { background:#4a3a2e; color:#e0b07e; }
.pos-OTHER { background:#2a2c35; color:#8a8a96; }

.summary-box { background:linear-gradient(90deg,rgba(200,169,110,.08),transparent); border-left:3px solid var(--gold); padding:9px 13px; border-radius:0 8px 8px 0; margin-bottom:7px; font-size:.87rem; line-height:1.5; }
.summary-box .rank-badge { background:var(--gold); color:#0e0f11; font-size:.62rem; font-weight:700; padding:1px 7px; border-radius:10px; margin-right:5px; }

.stats-row { display:flex; gap:10px; }
.stat-box { flex:1; background:var(--card2); border-radius:10px; padding:10px; text-align:center; }
.stat-box .stat-value { font-size:1.4rem; font-weight:700; color:var(--gold); }
.stat-box .stat-label { font-size:.67rem; color:var(--mute); text-transform:uppercase; letter-spacing:.4px; }

.lang-badge { display:inline-block; background:var(--card2); border:1px solid var(--bdr); border-radius:20px; padding:4px 14px; font-size:.78rem; color:var(--gold); font-weight:600; margin-bottom:10px; }

::-webkit-scrollbar { width:5px; }
::-webkit-scrollbar-thumb { background:var(--bdr); border-radius:3px; }
</style>""", unsafe_allow_html=True)


# â”€â”€ Sample Texts â”€â”€
EN_SAMPLE = ("There are broadly two types of extractive summarization tasks depending on what the "
"summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic "
"summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). "
"The second is query relevant summarization, sometimes called query-based summarization, which summarizes "
"objects specific to a query. Summarization systems are able to create both query relevant text summaries and "
"generic machine-generated summaries depending on what the user needs. An example of a summarization problem "
"is document summarization, which attempts to automatically produce an abstract from a given document. "
"Sometimes one might be interested in generating a summary from a single source document, while others can "
"use multiple source documents (for example, a cluster of articles on the same topic). This problem is called "
"multi-document summarization. A related application is summarizing news articles. Imagine a system, which "
"automatically pulls together news articles on a given topic (from the web), and concisely represents the "
"latest news as a summary. Image collection summarization is another application example of automatic "
"summarization. It consists in selecting a representative set of images from a larger set of images. A summary "
"in this context is useful to show the most representative images of results in an image collection exploration "
"system. Video summarization is a related domain, where the system automatically creates a trailer of a long "
"video. This also has applications in consumer or personal videos, where one might want to skip the boring or "
"repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious "
"activity, while ignoring all the boring and redundant frames captured.")

FR_SAMPLE = ("Il existe essentiellement deux types de tÃ¢ches de rÃ©sumÃ© extractif en fonction de ce sur quoi "
"se concentre le programme de rÃ©sumÃ©. Le premier est le rÃ©sumÃ© gÃ©nÃ©rique, qui vise Ã  obtenir un rÃ©sumÃ© "
"gÃ©nÃ©rique ou abstrait de la collection (qu'il s'agisse de documents, d'ensembles d'images, de vidÃ©os, "
"d'articles de presse, etc.). Le second est le rÃ©sumÃ© pertinent pour une requÃªte, parfois appelÃ© rÃ©sumÃ© basÃ© "
"sur une requÃªte, qui rÃ©sume des objets spÃ©cifiques Ã  une requÃªte. Les systÃ¨mes de rÃ©sumÃ© sont capables de "
"crÃ©er Ã  la fois des rÃ©sumÃ©s textuels pertinents pour une requÃªte et des rÃ©sumÃ©s gÃ©nÃ©rÃ©s automatiquement en "
"fonction des besoins de l'utilisateur. Un exemple de problÃ¨me de rÃ©sumÃ© est le rÃ©sumÃ© de documents, qui tente "
"de produire automatiquement un rÃ©sumÃ© Ã  partir d'un document donnÃ©. Parfois, on peut souhaiter gÃ©nÃ©rer un "
"rÃ©sumÃ© Ã  partir d'un seul document source, tandis que d'autres peuvent utiliser plusieurs documents sources "
"(par exemple, un ensemble d'articles sur le mÃªme sujet). Ce problÃ¨me est appelÃ© rÃ©sumÃ© multi-documents. Une "
"application connexe est le rÃ©sumÃ© d'articles d'actualitÃ©. Imaginez un systÃ¨me qui rassemble automatiquement "
"des articles d'actualitÃ© sur un sujet donnÃ© (Ã  partir du Web) et reprÃ©sente de maniÃ¨re concise les derniÃ¨res "
"informations sous forme de rÃ©sumÃ©. Le rÃ©sumÃ© d'une collection d'images est un autre exemple d'application de "
"rÃ©sumÃ© automatique. Il consiste Ã  sÃ©lectionner un ensemble reprÃ©sentatif d'images parmi un ensemble plus large "
"d'images. Dans ce contexte, un rÃ©sumÃ© est utile pour montrer les images les plus reprÃ©sentatives des rÃ©sultats "
"dans un systÃ¨me d'exploration de collections d'images. La vidÃ©o rÃ©sumÃ©e est un domaine connexe, oÃ¹ le systÃ¨me "
"crÃ©e automatiquement une bande-annonce d'une longue vidÃ©o. Cela trouve Ã©galement des applications dans les "
"vidÃ©os grand public ou personnelles, oÃ¹ l'on peut vouloir passer les actions ennuyeuses ou rÃ©pÃ©titives. De "
"mÃªme, dans les vidÃ©os de surveillance, on souhaiterait extraire les activitÃ©s importantes et suspectes, tout "
"en ignorant les images ennuyeuses et redondantes capturÃ©es.")


# â”€â”€ Language Config â”€â”€
LANGS = {
    "ğŸ‡¬ğŸ‡§ English": {"model":"en_core_web_sm", "stopwords":EN_STOP, "flag":"ğŸ‡¬ğŸ‡§", "name":"English", "placeholder":"Paste your text â€¦", "sample":EN_SAMPLE},
    "ğŸ‡«ğŸ‡· French":  {"model":"fr_core_news_sm","stopwords":FR_STOP, "flag":"ğŸ‡«ğŸ‡·", "name":"French",  "placeholder":"Collez votre texte â€¦","sample":FR_SAMPLE},
}

# POS tag â†’ CSS class
POS_CLASS = {"NOUN":"pos-NOUN", "VERB":"pos-VERB", "ADJ":"pos-ADJ", "ADV":"pos-ADV"}

# Legend colors for Token Tags tab
LEGEND_ITEMS = [("NOUN","#7eaee0"),("VERB","#b07ee0"),("ADJ","#7ee0a8"),("ADV","#e0b07e"),("OTHER","#8a8a96")]


# â”€â”€ Model Loader (auto-downloads if missing) â”€â”€
@st.cache_resource(show_spinner="Loading model â€¦")
def load_model(model_name):
    try:
        return spacy.load(model_name)
    except OSError:
        from spacy.cli import download
        download(model_name)
        return spacy.load(model_name)


# â”€â”€ Helper: Word Frequency â”€â”€
def calc_freq(doc, stopwords):
    count = {}
    for token in doc:
        word = token.text.lower()
        if word not in stopwords and word not in punctuation and word.strip():
            count[word] = count.get(word, 0) + 1
    mx = max(count.values()) if count else 1
    return {w: round(c / mx, 4) for w, c in count.items()}


# â”€â”€ Helper: Extractive Summary â”€â”€
def calc_summary(doc, freq, ratio):
    sents, scores = list(doc.sents), {}
    for sent in sents:
        for token in sent:
            if token.text.lower() in freq:
                scores[sent] = scores.get(sent, 0) + freq[token.text.lower()]
    top = nlargest(max(1, int(len(sents) * ratio)), scores, key=scores.get)
    return top, scores


# â”€â”€ Helper: Frequency Bar Chart â”€â”€
def plot_freq(freq, top_n):
    items  = sorted(freq.items(), key=lambda x: -x[1])[:top_n]
    words  = [i[0] for i in items]
    values = [i[1] for i in items]

    fig, ax = plt.subplots(figsize=(10, max(3.5, top_n * 0.3)))
    fig.patch.set_facecolor("#161820")
    ax.set_facecolor("#161820")
    ax.barh(words[::-1], values[::-1], color="#c8a96e", edgecolor="none", height=0.6)
    ax.set_xlabel("Normalized Frequency", color="#6b6b73", fontsize=9)
    ax.tick_params(colors="#e8e6e0", labelsize=9)
    ax.spines["top"].set_visible(False)
    ax.spines["right"].set_visible(False)
    ax.spines["bottom"].set_color("#2a2c35")
    ax.spines["left"].set_color("#2a2c35")
    fig.tight_layout()
    return fig


# â”€â”€ Helper: Word Cloud â”€â”€
def plot_wc(text):
    cloud = WordCloud(width=900, height=360, background_color="#161820", colormap="plasma", max_words=120).generate(text)
    fig, ax = plt.subplots(figsize=(11, 4))
    fig.patch.set_facecolor("#161820")
    ax.set_facecolor("#161820")
    ax.imshow(cloud, interpolation="bilinear")
    ax.axis("off")
    fig.tight_layout(pad=0.4)
    return fig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  SIDEBAR
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.markdown("### ğŸŒ NLP Text Analyzer")
    st.caption("Powered by spaCy")
    st.divider()
    selected_lang  = st.selectbox("ğŸŒ Select Language", options=list(LANGS.keys()))
    cfg            = LANGS[selected_lang]
    st.divider()
    summary_ratio  = st.slider("ğŸ“Š Summary Ratio", 0.1, 0.9, 0.4, 0.05)
    top_n_words    = st.slider("ğŸ·ï¸ Top-N Words", 5, 40, 15)
    st.divider()
    st.markdown(f"**Model:** `{cfg['model']}`\n**Language:** {cfg['flag']} {cfg['name']}")


# â”€â”€ Load Model â”€â”€
nlp       = load_model(cfg["model"])
stopwords = set(cfg["stopwords"])


# â”€â”€ Header â”€â”€
st.markdown(f'<div style="background:linear-gradient(135deg,#1a1620,#0e0f11);border:1px solid #2a2c35;padding:1.6rem 2rem;border-radius:12px;margin-bottom:12px;"><h1 style="margin:0;font-size:1.8rem;color:#e8e6e0;">{cfg["flag"]} <span style="color:#c8a96e;">Text Analyzer</span></h1><p style="margin:4px 0 0;color:#6b6b73;font-size:.85rem;">Tokenization Â· POS Tagging Â· Lemmatization Â· Summarization Â· Word Cloud</p></div>', unsafe_allow_html=True)


# â”€â”€ Input Section â”€â”€
st.markdown('<div class="card">', unsafe_allow_html=True)
st.markdown(f'<div class="lang-badge">{cfg["flag"]} {cfg["name"]} Mode</div>', unsafe_allow_html=True)

input_text = st.text_area("Input", value=cfg["sample"], height=150, label_visibility="collapsed", placeholder=cfg["placeholder"], key=selected_lang)

col1, col2 = st.columns([1, 5])
analyze_clicked = col1.button("âš¡ Analyze")
if col2.button("â†º Reset"):
    st.rerun()
st.markdown('</div>', unsafe_allow_html=True)

if not input_text.strip():
    st.warning("Kuch text dalo please.")
    st.stop()


# â”€â”€ Run NLP â”€â”€
with st.spinner("Analyzing â€¦"):
    doc             = nlp(input_text)
    word_freq       = calc_freq(doc, stopwords)
    summary, scores = calc_summary(doc, word_freq, summary_ratio)
    all_tokens      = list(doc)
    all_sentences   = list(doc.sents)

# Analyze confirmation
if analyze_clicked:
    st.markdown('<div style="background:rgba(126,174,224,.1);border-left:3px solid #7eaee0;padding:8px 13px;border-radius:0 8px 8px 0;color:#7eaee0;font-size:.82rem;margin-bottom:8px;">âœ… Analysis complete!</div>', unsafe_allow_html=True)


# â”€â”€ Stats Row (loop se banao â€” no repeated HTML blocks) â”€â”€
stats = [("Tokens", len(all_tokens)), ("Sentences", len(all_sentences)), ("Unique Words", len(word_freq)), ("Summary Sents", len(summary))]
stats_html = '<div class="card" style="padding:.75rem 1rem;"><div class="stats-row">'
for label, value in stats:
    stats_html += f'<div class="stat-box"><div class="stat-value">{value}</div><div class="stat-label">{label}</div></div>'
stats_html += '</div></div>'
st.markdown(stats_html, unsafe_allow_html=True)


# â”€â”€ Tabs â”€â”€
tab_tokens, tab_table, tab_summary, tab_freq, tab_cloud = st.tabs(["ğŸ·ï¸ Tokens","ğŸ“‹ Table","ğŸ“ Summary","ğŸ“Š Frequency","â˜ï¸ Word Cloud"])


# â”€â”€ TAB 1: Token Tags â”€â”€
with tab_tokens:
    st.markdown('<div class="card">', unsafe_allow_html=True)

    # Legend (loop se banao)
    legend_html = '<div style="display:flex;gap:16px;flex-wrap:wrap;margin-bottom:12px;">'
    for name, color in LEGEND_ITEMS:
        legend_html += f'<div style="display:flex;align-items:center;gap:6px;font-size:.73rem;color:#6b6b73;"><div style="width:10px;height:10px;border-radius:3px;background:{color};"></div>{name}</div>'
    legend_html += '</div>'

    # Token tags
    tags_html = '<div style="display:flex;flex-wrap:wrap;gap:4px;">'
    for token in all_tokens:
        tags_html += f'<div class="token-tag {POS_CLASS.get(token.pos_,"pos-OTHER")}"><span class="token-word">{token.text}</span><span class="token-meta">{token.pos_} Â· {token.lemma_}</span></div>'
    tags_html += '</div>'

    st.markdown(legend_html + tags_html + '</div>', unsafe_allow_html=True)


# â”€â”€ TAB 2: Table â”€â”€
with tab_table:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    df = pd.DataFrame([{"#":i+1,"Token":t.text,"POS":t.pos_,"Tag":t.tag_,"Lemma":t.lemma_,"Dep":t.dep_,"Stop":t.is_stop,"Punct":t.is_punct} for i,t in enumerate(all_tokens)])
    st.dataframe(df, hide_index=True, use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)


# â”€â”€ TAB 3: Summary â”€â”€
with tab_summary:
    st.markdown('<div class="card">', unsafe_allow_html=True)

    # Rank by score descending
    ranked   = sorted([(s, scores.get(s, 0)) for s in summary], key=lambda x: -x[1])
    rank_map = {id(s): r + 1 for r, (s, _) in enumerate(ranked)}

    for sent in summary:
        st.markdown(f'<div class="summary-box"><span class="rank-badge">#{rank_map[id(sent)]}</span>{sent.text}</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

    # Scores table
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.caption("All Sentence Scores")
    df_scores = pd.DataFrame([{"#":i+1,"Sentence":(s.text[:80]+"â€¦") if len(s.text)>80 else s.text,"Score":round(scores.get(s,0),3),"In Summary":s in summary} for i,s in enumerate(all_sentences)])
    st.dataframe(df_scores, hide_index=True, use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)


# â”€â”€ TAB 4: Frequency â”€â”€
with tab_freq:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.pyplot(plot_freq(word_freq, top_n_words), use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)


# â”€â”€ TAB 5: Word Cloud â”€â”€
with tab_cloud:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.pyplot(plot_wc(input_text), use_container_width=True)
    st.markdown('</div>', unsafe_allow_html=True)
